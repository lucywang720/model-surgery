python -m run_pplm_discrim_train --dataset=toxic --dataset_fp datasets/toxic.txt --pretrained_model llama2-7b --epochs 20 --output_fp probe_llama2 --batch_size 16 --save_model
